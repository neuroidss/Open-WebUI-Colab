{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMC+6nyIOB6zPYDJ6M8tkBL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuroidss/Open-WebUI-Colab/blob/main/similar_articles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KduzL391PJV",
        "outputId": "9c9e9400-ccba-49ee-ca89-79012375cb1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/Cornell-University/arxiv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Ffn_4C1dlG",
        "outputId": "abf17f9d-01db-4d28-afec-a171e8cbed68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: neuroidss\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/Cornell-University/arxiv\n",
            "Downloading arxiv.zip to ./arxiv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.39G/1.39G [00:20<00:00, 72.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "#category_map = {\n",
        "#'cs.AI': 'Artificial Intelligence',\n",
        "#'cs.CL': 'Computation and Language',\n",
        "#'cs.CV': 'Computer Vision and Pattern Recognition',\n",
        "#'cs.IR': 'Information Retrieval',\n",
        "#'cs.LG': 'Machine Learning',\n",
        "#}\n",
        "\n",
        "#def clean_categories(x):\n",
        "#    cat_text = ''\n",
        "#    cat_list = x.split(' ')\n",
        "#    for i, item in enumerate(cat_list):\n",
        "#        cat_name = category_map[item]\n",
        "#        if cat_name != 'Not available':\n",
        "#            if i == 0: cat_text = cat_name\n",
        "#            else:      cat_text = cat_text + ', ' + cat_name\n",
        "#    cat_text = cat_text.strip()\n",
        "#    return cat_text\n",
        "\n",
        "def clean_text(x):\n",
        "    new_text = x.replace(\"\\n\", \" \")\n",
        "    new_text = new_text.strip()\n",
        "    return new_text\n",
        "\n",
        "def clean_dataframe():\n",
        "    columns = ['id', 'authors', 'title', 'categories', 'abstract']\n",
        "\n",
        "    # Specify the folders containing the JSON and schema files\n",
        "#    filepath = '/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json'\n",
        "    filepath = 'arxiv/'+'arxiv-metadata-oai-snapshot.json'\n",
        "    data = []\n",
        "\n",
        "    # Open the file and read line by line\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            doc = json.loads(line)\n",
        "            lst = [doc['id'], doc['authors'], doc['title'], doc['categories'], doc['abstract']]\n",
        "            data.append(lst)\n",
        "\n",
        "    arxiv_data = pd.DataFrame(data=data, columns=columns)\n",
        "#    topics = ['cs.AI', 'cs.CV', 'cs.IR', 'cs.LG', 'cs.CL']\n",
        "\n",
        "#    filtered_data                  = arxiv_data[arxiv_data['categories'].isin(topics)]\n",
        "    filtered_data                  = arxiv_data\n",
        "#    filtered_data['categories']    = filtered_data['categories'].apply(clean_categories)\n",
        "    filtered_data['title']         = filtered_data['title'].apply(clean_text)\n",
        "    filtered_data['abstract']      = filtered_data['abstract'].apply(clean_text)\n",
        "    filtered_data['prepared_text'] = filtered_data['title'] + ' \\n ' + filtered_data['abstract']\n",
        "    return filtered_data\n",
        "\n",
        "df = clean_dataframe()\n",
        "df.to_csv('arxiv/'+'arxiv-metadata-oai-snapshot.csv', encoding='utf-8', index=False)\n"
      ],
      "metadata": {
        "id": "kZiyyT-O1oNF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "arxiv_data = pd.read_csv('arxiv/'+\"arxiv-metadata-oai-snapshot.csv\")\n",
        "\n",
        "#topics = ['cs.AI', 'cs.CV', 'cs.IR', 'cs.LG', 'cs.CL']\n",
        "\n",
        "#filtered_data                  = arxiv_data[arxiv_data['categories'].isin(topics)]\n",
        "#filtered_data                  = arxiv_data\n",
        "#filtered_data['prepared_text'] = filtered_data['title'] + ' \\n ' + filtered_data['abstract']\n",
        "\n",
        "#print(filtered_data.shape)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "#df = pd.DataFrame({\n",
        "#    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "#    'Age': [25, 30, 35],\n",
        "#    'Country': ['USA', 'Canada', 'Mexico']\n",
        "#})\n",
        "\n",
        "# Define a search function\n",
        "def search_string(s, search):\n",
        "    return search in str(s).lower()\n",
        "\n",
        "filtered_arxiv_data = arxiv_data.loc[:, arxiv_data.columns == 'prepared_text']\n",
        "\n",
        "# Search for the string 'al' in all columns\n",
        "mask = filtered_arxiv_data.apply(lambda x: x.map(lambda s: search_string(s, 'eeg')))\n",
        "\n",
        "# Filter the DataFrame based on the mask\n",
        "filtered_arxiv_data = filtered_arxiv_data.loc[mask.any(axis=1)]\n",
        "\n",
        "# Search for the string 'al' in all columns\n",
        "mask = filtered_arxiv_data.apply(lambda x: x.map(lambda s: search_string(s, 'working')))\n",
        "\n",
        "# Filter the DataFrame based on the mask\n",
        "filtered_arxiv_data = filtered_arxiv_data.loc[mask.any(axis=1)]\n",
        "\n",
        "# Search for the string 'al' in all columns\n",
        "mask = filtered_arxiv_data.apply(lambda x: x.map(lambda s: search_string(s, 'memory')))\n",
        "\n",
        "# Filter the DataFrame based on the mask\n",
        "filtered_arxiv_data = filtered_arxiv_data.loc[mask.any(axis=1)]\n",
        "\n",
        "print(filtered_arxiv_data)\n",
        "\n",
        "filtered_arxiv_data.to_csv('arxiv/'+'arxiv-metadata-oai-snapshot_eeg_working_memory.csv', encoding='utf-8', index=False)\n",
        "\n",
        "import os\n",
        "\n",
        "filename = 'arxiv/'+\"arxiv-metadata-oai-snapshot_working_memory/out.csv\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "for index, row in filtered_arxiv_data.iterrows():\n",
        "    row.to_csv('arxiv/'+'arxiv-metadata-oai-snapshot_working_memory/out_{index}.csv'.format(index=index), encoding='utf-8', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-EusuEB1szk",
        "outputId": "ba3f154c-2707-4254-e9fe-812d75539165"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-eb587e88e4bd>:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  arxiv_data = pd.read_csv('arxiv/'+\"arxiv-metadata-oai-snapshot.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             prepared_text\n",
            "671220   Filter Bank Common Spatial Patterns in Mental ...\n",
            "721571   Comparison of Network Analysis Approaches on E...\n",
            "756442   Assessing Functional Neural Connectivity as an...\n",
            "858570   Decline of long-range temporal correlations in...\n",
            "858571   The interplay between long- and short-range te...\n",
            "952632   Use of Eye-Tracking Technology to Investigate ...\n",
            "1189540  Decoding Working Memory Load from EEG with LST...\n",
            "1256255  Inhibition and Set-Shifting Tasks in Central E...\n",
            "1290981  EEG source localization analysis in epileptic ...\n",
            "1311364  Application of statistical analysis to working...\n",
            "1332709  Single-channel EEG features during n-back task...\n",
            "1369789  BCI learning induces core-periphery reorganiza...\n",
            "1427483  Coherence of Working Memory Study Between Deep...\n",
            "1432301  Ridge-penalized adaptive Mantel test and its a...\n",
            "1433999  A Pilot Study on Visually Stimulated Cognitive...\n",
            "1484533  Cross-Subject Domain Adaptation for Classifyin...\n",
            "1566256  Methodology and feasibility of neurofeedback t...\n",
            "1576240  Differential EEG Characteristics during Workin...\n",
            "1638716  Is the Contralateral Delay Activity (CDA) a ro...\n",
            "1667376  Infrared Radiation of Graphene Electrothermal ...\n",
            "1690368  Significant changes in EEG neural oscillations...\n",
            "1761831  Changes in Power and Information Flow in Resti...\n",
            "1951670  Impact of Nap on Performance in Different Work...\n",
            "1953414  Designing and Evaluating an Adaptive Virtual R...\n",
            "1988407  Using i-vectors for subject-independent cross-...\n",
            "2016128  FAST functional connectivity implicates P300 c...\n",
            "2056918  Bayesian Functional Connectivity and Graph Con...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openwebui_host='rnqtn-34-16-171-130.a.free.pinggy.link'\n",
        "token=\"sk-2c12941010fb4de994a3ca4ae484f68b\"\n",
        "model=\"hf.co/mradermacher/CoderO1-DeepSeekR1-Coder-14B-Preview-GGUF:Q4_K_M\""
      ],
      "metadata": {
        "id": "HerTkwqW5WmF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def upload_file(token, file_path):\n",
        "    url = 'http://'+openwebui_host+':3000/api/v1/files/'\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {token}',\n",
        "        'Accept': 'application/json'\n",
        "    }\n",
        "    files = {'file': open(file_path, 'rb')}\n",
        "    response = requests.post(url, headers=headers, files=files)\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "Mz0iN_Js4rZl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def add_file_to_knowledge(token, knowledge_id, file_id):\n",
        "    url = f'http://'+openwebui_host+':3000/api/v1/knowledge/{knowledge_id}/file/add'\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {token}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "    data = {'file_id': file_id}\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "jSknImJG4tvV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_ids=[]\n",
        "for file in os.listdir('arxiv/'+'arxiv-metadata-oai-snapshot_working_memory'):\n",
        "  if file.endswith(\".csv\"):\n",
        "    print(os.path.join('arxiv/'+'arxiv-metadata-oai-snapshot_working_memory', file))\n",
        "    file_path='arxiv/'+'arxiv-metadata-oai-snapshot_working_memory/'+file\n",
        "    response_json = upload_file(token, file_path)\n",
        "    print(response_json)\n",
        "#    knowledge_id\n",
        "    file_id=response_json['id']\n",
        "    file_ids.append(file_id)\n",
        "#    add_file_to_knowledge(token, knowledge_id, file_id)\n",
        "#    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "_w88AZlH4btX",
        "outputId": "a696b766-1aff-42c8-9640-d5788b8c1718"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arxiv/arxiv-metadata-oai-snapshot_working_memory/out_1566256.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ConnectTimeout",
          "evalue": "HTTPConnectionPool(host='rnqtn-34-16-171-130.a.free.pinggy.link', port=3000): Max retries exceeded with url: /api/v1/files/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7905c52d8610>, 'Connection to rnqtn-34-16-171-130.a.free.pinggy.link timed out. (connect timeout=None)'))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             sock = connection.create_connection(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             conn.request(\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             raise ConnectTimeoutError(\n\u001b[0m\u001b[1;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPConnection object at 0x7905c52d8610>, 'Connection to rnqtn-34-16-171-130.a.free.pinggy.link timed out. (connect timeout=None)')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    842\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreason\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='rnqtn-34-16-171-130.a.free.pinggy.link', port=3000): Max retries exceeded with url: /api/v1/files/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7905c52d8610>, 'Connection to rnqtn-34-16-171-130.a.free.pinggy.link timed out. (connect timeout=None)'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-693afa35efb4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arxiv/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'arxiv-metadata-oai-snapshot_working_memory'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'arxiv/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'arxiv-metadata-oai-snapshot_working_memory/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#    knowledge_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ce253d7d2f31>\u001b[0m in \u001b[0;36mupload_file\u001b[0;34m(token, file_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m     }\n\u001b[1;32m      9\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;31m# TODO: Remove this in 3.0.0: see #2811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNewConnectionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mConnectTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectTimeout\u001b[0m: HTTPConnectionPool(host='rnqtn-34-16-171-130.a.free.pinggy.link', port=3000): Max retries exceeded with url: /api/v1/files/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7905c52d8610>, 'Connection to rnqtn-34-16-171-130.a.free.pinggy.link timed out. (connect timeout=None)'))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def chat_with_file(token, model, query, file_id):\n",
        "    url = 'http://'+openwebui_host+':3000/api/chat/completions'\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {token}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "    payload = {\n",
        "        'model': model,\n",
        "        'messages': [{'role': 'user', 'content': query}],\n",
        "        'files': [{'type': 'file', 'id': file_id}]\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    return response.json()\n",
        "\n",
        "def chat_with_files(token, model, query, file_ids):\n",
        "    url = 'http://'+openwebui_host+':3000/api/chat/completions'\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {token}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    files = []\n",
        "    for file_id in file_ids:\n",
        "        files.append({'type': 'file', 'id': file_id})\n",
        "    payload = {\n",
        "        'model': model,\n",
        "        'messages': [{'role': 'user', 'content': query}],\n",
        "        'files': files\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "LgyGtkuS42gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query='make psytrance visuals, controlled by simulated eeg stream, based on working memory increase science, put css and js inside single html file. all comments leave only inside html block. no text output outside html block'\n",
        "for file_id in file_ids:\n",
        "#  response_json = chat_with_file(token, model, query, file_id)\n",
        "  file_ids_plus = file_ids.copy()\n",
        "  file_ids_plus.append(file_id)\n",
        "  response_json = chat_with_files(token, model, query, file_ids_plus)\n",
        "\n",
        "  print(response_json)\n",
        "  import os\n",
        "\n",
        "  filename = 'arxiv/'+\"arxiv-metadata-oai-snapshot_working_memory/html/out.html\"\n",
        "  os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "  filename = 'arxiv/'+'arxiv-metadata-oai-snapshot_working_memory/html/out_'+file_id+'.html'\n",
        "  f = open(filename, \"w\")\n",
        "  response_message_content = response_json['choices'][0]['message']['content']\n",
        "  created_html = ''\n",
        "  for response_message_content_split in response_message_content.split(\"```\"):\n",
        "    split_html = response_message_content_split.split(\"html\\n\")\n",
        "    if len(split_html)>1 and len(split_html[0])==0 and len(created_html)==0:\n",
        "      created_html = split_html[1]\n",
        "  f.write(created_html)\n",
        "  f.close()\n",
        "#  import IPython\n",
        "#  IPython.display.HTML(filename=filename)\n",
        "#  from IPython.display import IFrame\n",
        "#  IFrame(src=filename, width=900, height=600)"
      ],
      "metadata": {
        "id": "Esbn_CDh45Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def chat_with_collection(token, model, query, collection_id):\n",
        "    url = 'http://'+openwebui_host+':3000/api/chat/completions'\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {token}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "    payload = {\n",
        "        'model': model,\n",
        "        'messages': [{'role': 'user', 'content': query}],\n",
        "        'files': [{'type': 'collection', 'id': collection_id}]\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "u0FHJrAw481c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}